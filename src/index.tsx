
import { QuarkElement, customElement, state } from "quarkc"
import style from "./index.less?inline"
import axios from 'axios';

import VConsole from 'vconsole';
const vConsole = new VConsole({ theme: 'dark' });

@customElement({ tag: "my-app", style })
class MyApp extends QuarkElement {
  #printInterval

  @state()
  myQuestion: string = 'æ¯”å¦‚ï¼šå·´ä»¥å†²çªå†å²åŸå› ï¼Ÿ'

  @state()
  audioResponseFilePath: string = ''

  @state()
  loading: Boolean = false

  @state()
  fetchLoading: Boolean = false

  componentDidMount() {
    this.speech();
  }

	render() {
		return (
      <>
        <section className="result-module">
          <div>
            <h4>æé—®ï¼š{ this.myQuestion }</h4>
          </div>

          {
            this.audioResponseFilePath ?
            <div className="wave-icon">
              <img src="https://media.giphy.com/media/l4XfgLyXAnyzCh7vfY/giphy.gif" alt="" />
            </div> : null
          }

          <p id="chat">
            {
              this.fetchLoading ?  'Loading...' : <>
              {
                !this.audioResponseFilePath ?
                  <>
                  <h5>ä»Šæ—¥å…¨ç½‘çƒ­ç‚¹æ–°é—»ï¼š</h5>
                  <li>
                    <strong>1</strong>  ğŸ”¥ å·´ä»¥å†²çª
                  </li>
                  <li>
                    <strong>2</strong> ä¼Šæ‹‰å…‹æ°‘å…µæ­¦è£…è¢­å‡»é©»å™ç¾å†›
                  </li>
                  <li>
                    <strong>3</strong> å’¸é±¼å›åº”å¤§å­¦ç”Ÿåœ¨å¹³å°æŒ‚å­¦æ ¡
                  </li>
                  <li>
                    <span>4</span> ä¼Šæ‹‰å…‹æ°‘å…µæ­¦è£…è¢­å‡»é©»å™ç¾å†›
                  </li>
                  <li>
                    <span>5</span> ä¼Šæ‹‰å…‹æ°‘å…µæ­¦è£…è¢­å‡»é©»å™ç¾å†›
                  </li>
                  </> : null
              }

              </>
            }
          </p>

          {
            this.audioResponseFilePath ?
            <audio id="audio" controls autoplay>
              <source src={this.audioResponseFilePath} type="audio/mpeg" />
            </audio> : ''
          }
        </section>

        <div className="type">
          <div class="btn" id="start-btn">
            {this.loading ? 'æ­£åœ¨è¯†åˆ«' :'å¼€å§‹è¯†åˆ«'}
          </div>
        </div>
      </>
		);
	}

  init = () => {
    const _this = this
    const dom = this.shadowRoot.querySelector<HTMLElement>('#chat')
    const audio = this.shadowRoot.querySelector<HTMLVideoElement>('#audio')
    dom.innerText = ''
    _this.audioResponseFilePath = ''
    _this.loading = false
    this.#printInterval = null
    _this.setCursorStatus('end')

    audio?.pause();
  }

  fetchData = (val) => {
    const _this = this
    _this.fetchLoading = true

    // init data
    _this.init()

    // è¯·æ±‚æ•°æ®
    axios.post('http://47.103.124.169:3002/chat-new-without-stream', {
      user_id: "123",
      request_text: val,
    })
      .then(function (response) {
        const {data} = response;
        console.log(data.text, data.audio_response_file_path, 1111);

        _this.fetchLoading = false
        _this.audioResponseFilePath = data.audio_response_file_path

        // audio.play();

        _this.printText(data.text.response_text)
      })
      .catch(err => {
        console.log(err, 222);
        _this.printText('è¯·é‡æ–°æé—®ï¼Œæ²¡æœ‰æ‰¾åˆ°æœ‰ç”¨çš„ä¿¡æ¯~')
        _this.fetchLoading = false;

      })
  }

  printText = (content, speed = 50) => {
    const _this = this
    const dom = this.shadowRoot.querySelector<HTMLElement>('#chat')

    let index = 0
    _this.setCursorStatus('typing')

    this.#printInterval = setInterval(() => {
      dom.innerText += content[index]
      index++
      if (index >= content.length) {
        _this.setCursorStatus('end')
        clearInterval(this.#printInterval)
      }
    }, speed)
  }


  // è®¾ç½®domçš„å…‰æ ‡çŠ¶æ€
  setCursorStatus = (status) => {
    const classList = {
      loading: 'typing blinker',
      typing: 'typing',
      end: '',
    }
    const dom = this.shadowRoot.querySelector('#chat')
    dom.className = classList[status]
  }

  // å½•å…¥å£°éŸ³ï¼Œè½¬æ–‡å­—
  speech = () => {
    const btn = this.shadowRoot.querySelector("#start-btn")
    const _this = this;

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition()

    recognition.continuous = false
    // recognition.lang = 'en-US'
    recognition.lang = 'zh-CN'
    recognition.interimResults = false
    recognition.maxAlternatives = 1

    // è¯´è¯ç»“æŸ
    recognition.onspeechend = function() {
      console.log('onspeechend');
      recognition.stop()
    }

    // ç»“æŸçš„ç»“æœè¿”å›cb
    recognition.onresult = (e) => {
      // _this.init()
      console.log(e, 'onresult');

        const text = event.results[0][0].transcript
        btn.className = "btn"

        _this.myQuestion = text
        _this.loading = false

        _this.fetchData(text)
    }

    recognition.onerror = function(event) {
        console.log('onerror: ' + event.error)
        // _this.audioResponseFilePath = ''
        // _this.loading = false

        _this.init()

        btn.className = "btn"
    }

    btn.addEventListener("click", (e: any) => {

        _this.init()

        e.target.className = "btn start"
        if(this.loading) return;
        recognition.start()
        this.loading = true
    })

  }
}
